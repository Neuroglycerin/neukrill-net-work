!obj:pylearn2.train.Train {
    dataset: &train !obj:neukrill_net.image_directory_dataset.ListDataset {
        transformer: !obj:neukrill_net.augment.RandomAugment {
                units: 'float',
                rotate: -1,
                flip: 1,
                shunt: 0.05,
                scale: 0.09,
                scale_asym: 0.009,
                shear: 6,
                resize: %(final_shape)s,
                normalise: {global_or_pixel: 'global',
                            mu: %(mu)s,
                            sigma: %(sigma)s}
        },
        settings_path: %(settings_path)s,
        run_settings_path: %(run_settings_path)s,
        prepreprocessing: {
            resize: %(final_shape)s,
            resize_order: 0.75,
        },
        #training_set_mode: "test"
    },
    model: !obj:pylearn2.models.mlp.MLP {
        batch_size: &batch_size 128,
        input_space: !obj:pylearn2.space.Conv2DSpace {
            shape: %(final_shape)s,
            num_channels: 1,
            axes: ['b', 0, 1, 'c'],
        },
        layers: [ !obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: h1,
                     output_channels: 128,
                     irange: 0.02,
                     kernel_shape: [5, 5],
                     pool_shape: [3, 3],
                     pool_stride: [2, 2],
                     b_lr_scale: 2.,
                     max_kernel_norm: 0.9
                 },!obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: h2,
                     output_channels: 128,
                     irange: 0.0005,
                     kernel_shape: [3, 3],
                     pool_shape: [3, 3],
                     pool_stride: [2, 2],
                     border_mode: full,
                     b_lr_scale: 2.,
                     max_kernel_norm: 2.
                 }, !obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: h3,
                     output_channels: 128,
                     irange: 0.0005,
                     kernel_shape: [3, 3],
                     pool_shape: [3, 3],
                     pool_stride: [2, 2],
                     border_mode: full,
                     b_lr_scale: 2.,
                     max_kernel_norm: 2.
                 }, !obj:pylearn2.models.mlp.ConvRectifiedLinear {
                     layer_name: h4,
                     output_channels: 128,
                     irange: 0.0005,
                     kernel_shape: [3, 3],
                     pool_shape: [2, 2],
                     pool_stride: [2, 2],
                     border_mode: full,
                     b_lr_scale: 2.,
                     max_kernel_norm: 2.
                 }, !obj:pylearn2.models.mlp.RectifiedLinear {
                     dim: 1024,
                     max_col_norm: 1.8,
                     layer_name: h11,
                     istdev: .005,
                     init_bias: 0,
                     b_lr_scale: 2.,
                 }, !obj:pylearn2.models.mlp.FlattenerLayer {
                     raw_layer: !obj:pylearn2.models.mlp.CompositeLayer {
                     layer_name: 'y',
                     layers: [
                        !obj:pylearn2.models.mlp.Softmax {
                            n_classes: %(n_classes_1)i,
                            layer_name: y_1,
                            istdev: .01,
                            b_lr_scale: 2.,
                        },
                        !obj:pylearn2.models.mlp.Softmax {
                            n_classes: %(n_classes_2)i,
                            layer_name: y_2,
                            istdev: .01,
                            b_lr_scale: 2.,
                        },
                        !obj:pylearn2.models.mlp.Softmax {
                            n_classes: %(n_classes_3)i,
                            layer_name: y_3,
                            istdev: .01,
                            b_lr_scale: 2.,
                        },
                        !obj:pylearn2.models.mlp.Softmax {
                            n_classes: %(n_classes_4)i,
                            layer_name: y_4,
                            istdev: .01,
                            b_lr_scale: 2.,
                        },
                        !obj:pylearn2.models.mlp.Softmax {
                            n_classes: %(n_classes_5)i,
                            layer_name: y_5,
                            istdev: .01,
                            b_lr_scale: 2.,
                        },
                        !obj:pylearn2.models.mlp.Softmax {
                            n_classes: %(n_classes_6)i,
                            layer_name: y_6,
                            istdev: .01,
                            b_lr_scale: 2.,
                        }
                    ]
                }
                }
                ],
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        train_iteration_mode: even_shuffled_sequential,
        monitor_iteration_mode: even_sequential,
        batch_size: *batch_size,
        learning_rate: 0.5,
        learning_rule: !obj:neukrill_net.update_norm_monitor.UpdateNormMonitorLearningRule {
            base_learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {
                init_momentum: 0.00
            },
            decay: 0.9,
        },
        monitoring_dataset: {
                'train': *train,
                'valid' : !obj:neukrill_net.image_directory_dataset.ListDataset {
                            transformer: !obj:neukrill_net.augment.RandomAugment {
                                units: 'float',
                                rotate: 0,
                                flip: 0,
                                normalise: {global_or_pixel: 'global',
                                            mu: %(mu)s,
                                            sigma: %(sigma)s}
                        },
                    settings_path: %(settings_path)s,
                    run_settings_path: %(run_settings_path)s,
                    prepreprocessing: {
                        resize: %(final_shape)s,
                        resize_order: 0.75,
                    },
                    training_set_mode: "validation"
                }
        },
        cost: !obj:pylearn2.costs.cost.SumOfCosts { costs: [ 
            !obj:pylearn2.costs.mlp.dropout.Dropout {
                input_include_probs: {
                    h1 : 1.,
                    h2 : 1.,
                    h3 : 1.,
                    h4 : 1.,
                    h11 : 0.5,
                },
                input_scales: {
                    h1 : 1.,
                    h2 : 1.,
                    h3 : 1.,
                    h4 : 1.,
                    h11 : 2.,
                }
             },
             !obj:pylearn2.costs.mlp.WeightDecay {
                 coeffs : {
                     h1 : .0005,
                     h2 : .0005,
                     h3 : .0005,
                     h4 : .0005,
                     h11 : .0005,
                 }
             }
             ]
        },
        termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: 500
                },
            ]
        },
    },
    extensions: [
        !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
            start: 1,
            saturate: 200,
            final_momentum: 0.75
        },
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: valid_y_y_1_nll,
             save_path: '%(save_path)s'
        },
        !obj:pylearn2.training_algorithms.sgd.MonitorBasedLRAdjuster {
            high_trigger: 1.,
            low_trigger: 0.999,
            grow_amt: 1.05,
            shrink_amt: 0.9,
            max_lr: 1.,
            min_lr: 1e-5,
            channel_name: valid_y_y_1_nll
        }
    ],
    save_path: '%(alt_picklepath)s',
    save_freq: 1
}
