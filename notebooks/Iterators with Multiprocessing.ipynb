{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're wasting a bunch of time waiting for our iterators to produce minibatches when we're running epochs. Seems like we should probably precompute them while the minibatch is being run on the GPU. To do this involves using the [multiprocessing module][multi]. Since I've never used it before, here are my dev notes for writing this into the dataset iterators.\n",
    "\n",
    "[multi]: https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = multiprocessing.Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = range(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda x: x*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason _can't run these in the notebook_. So have to run them with subprocess like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(5)\n",
    "    print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(5)\n",
    "    print(p.map(f, np.array([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now doing this asynchronously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_cache', '_callback', '_chunksize', '_cond', '_job', '_number_left', '_ready', '_set', '_success', '_value', 'get', 'ready', 'successful', 'wait']\n",
      "[0, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(5)\n",
    "    r = p.map_async(f, np.array([0,1,2]))\n",
    "    print(dir(r))\n",
    "    print(r.get(timeout=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying to create an iterable that will precompute it's output using multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1025580452926798, 0.34677353277728845, 0.31839348399451078, 0.54494737993807252]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "class It(object):\n",
    "    def __init__(self,a):\n",
    "        # store an array (2D)\n",
    "        self.a = a\n",
    "        # initialise pool\n",
    "        self.p = Pool(4)\n",
    "        # initialise index\n",
    "        self.i = 0\n",
    "        # initialise pre-computed first batch\n",
    "        self.batch = self.p.map_async(f,self.a[self.i,:])\n",
    "        \n",
    "    def get(self):\n",
    "        return self.batch.get(timeout=1)\n",
    "    \n",
    "    def f(self,x):\n",
    "        return x**2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    it = It(np.random.randn(4,4))\n",
    "    print(it.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11632354861762748, 1.5191669861450494, 0.27348868876418703, 0.010258287939590853]\n",
      "[0.29734749705574992, 5.6932341844792448e-06, 2.6846188531586321, 1.1826209061013211]\n",
      "[0.85475358111289024, 0.0073300344874941128, 0.1075715401038779, 0.041012729304054182]\n",
      "[0.43303217578385272, 0.11516251129488242, 0.039813716356569974, 5.5441760979118655]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "class It(object):\n",
    "    def __init__(self,a):\n",
    "        # store an array (2D)\n",
    "        self.a = a\n",
    "        # initialise pool\n",
    "        self.p = Pool(4)\n",
    "        # initialise index\n",
    "        self.i = 0\n",
    "        # initialise pre-computed first batch\n",
    "        self.batch = self.p.map_async(f,self.a[self.i,:])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        # check if we've got something pre-computed to return\n",
    "        if self.batch:\n",
    "            # get the output\n",
    "            output = self.batch.get(timeout=1)\n",
    "            #output = self.batch\n",
    "            # prepare next batch\n",
    "            self.i += 1\n",
    "            if self.i < self.a.shape[0]:\n",
    "                self.p = Pool(4)\n",
    "                self.batch = self.p.map_async(f,self.a[self.i,:])\n",
    "                #self.batch = map(self.f,self.a[self.i,:])\n",
    "            else:\n",
    "                self.batch = False\n",
    "            return output\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    it = It(np.random.randn(4,4))\n",
    "    for a in it:\n",
    "        print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have to try and do a similar thing, but using the randomaugment function. In the following two cells one uses multiprocessiung and one that doesn't. Testing them by pretending to ask for a minibatch and then sleep, applying the RandomAugment function each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 ms, sys: 40 ms, total: 70 ms\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%python\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import neukrill_net.augment\n",
    "import time\n",
    "\n",
    "class It(object):\n",
    "    def __init__(self,a,f):\n",
    "        # store an array (2D)\n",
    "        self.a = a\n",
    "        # store the function\n",
    "        self.f = f\n",
    "        # initialise pool\n",
    "        self.p = Pool(4)\n",
    "        # initialise indices\n",
    "        self.inds = range(self.a.shape[0])\n",
    "        # pop a batch from top\n",
    "        self.batch_inds = [self.inds.pop(0) for _ in range(100)]\n",
    "        # initialise pre-computed first batch\n",
    "        self.batch = map(self.f,self.a[self.batch_inds,:])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        # check if we've got something pre-computed to return\n",
    "        if self.inds != []:\n",
    "            # get the output\n",
    "            output = self.batch\n",
    "            # prepare next batch\n",
    "            self.batch_inds = [self.inds.pop(0) for _ in range(100)]\n",
    "            self.p = Pool(4)\n",
    "            self.batch = map(self.f,self.a[self.batch_inds,:])\n",
    "            return output\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    f = neukrill_net.augment.RandomAugment(rotate=[0,90,180,270])\n",
    "    it = It(np.random.randn(10000,48,48),f)\n",
    "    for a in it:\n",
    "        time.sleep(0.01)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 ms, sys: 10 ms, total: 19 ms\n",
      "Wall time: 6.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%python\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import neukrill_net.augment\n",
    "import time\n",
    "\n",
    "class It(object):\n",
    "    def __init__(self,a,f):\n",
    "        # store an array (2D)\n",
    "        self.a = a\n",
    "        # store the function\n",
    "        self.f = f\n",
    "        # initialise pool\n",
    "        self.p = Pool(8)\n",
    "        # initialise indices\n",
    "        self.inds = range(self.a.shape[0])\n",
    "        # pop a batch from top\n",
    "        self.batch_inds = [self.inds.pop(0) for _ in range(100)]\n",
    "        # initialise pre-computed first batch\n",
    "        self.batch = self.p.map_async(f,self.a[self.batch_inds,:])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        # check if we've got something pre-computed to return\n",
    "        if self.inds != []:\n",
    "            # get the output\n",
    "            output = self.batch.get(timeout=1)\n",
    "            # prepare next batch\n",
    "            self.batch_inds = [self.inds.pop(0) for _ in range(100)]\n",
    "            #self.p = Pool(4)\n",
    "            self.batch = self.p.map_async(f,self.a[self.batch_inds,:])\n",
    "            return output\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    f = neukrill_net.augment.RandomAugment(rotate=[0,90,180,270])\n",
    "    it = It(np.random.randn(10000,48,48),f)\n",
    "    for a in it:\n",
    "        time.sleep(0.01)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 48, 48)\n",
      "(100, 48, 48, 1)\n",
      "CPU times: user 2 ms, sys: 11 ms, total: 13 ms\n",
      "Wall time: 2.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%python\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import neukrill_net.augment\n",
    "import time\n",
    "\n",
    "class It(object):\n",
    "    def __init__(self,a,f):\n",
    "        # store an array (2D)\n",
    "        self.a = a\n",
    "        # store the function\n",
    "        self.f = f\n",
    "        # initialise pool\n",
    "        self.p = Pool(8)\n",
    "        # initialise indices\n",
    "        self.inds = range(self.a.shape[0])\n",
    "        # pop a batch from top\n",
    "        self.batch_inds = [self.inds.pop(0) for _ in range(100)]\n",
    "        # initialise pre-computed first batch\n",
    "        self.batch = self.p.map_async(f,self.a[self.batch_inds,:])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        # check if we've got something pre-computed to return\n",
    "        if self.inds != []:\n",
    "            # get the output\n",
    "            output = self.batch.get(timeout=1)\n",
    "            # prepare next batch\n",
    "            self.batch_inds = [self.inds.pop(0) for _ in range(100)]\n",
    "            #self.p = Pool(4)\n",
    "            self.batch = self.p.map_async(f,self.a[self.batch_inds,:])\n",
    "            return output\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    f = neukrill_net.augment.RandomAugment(rotate=[0,90,180,270])\n",
    "    it = It(np.random.randn(10000,48,48),f)\n",
    "    for a in it:\n",
    "        print np.array(a).shape\n",
    "        print np.array(a).reshape(100,48,48,1).shape\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like, depending on the sleep time this should be about 5 times as fast."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
