{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-net-work\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import skimage\n",
    "import cv2\n",
    "import sklearn\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "from holoviews import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import neukrill_net.utils\n",
    "import neukrill_net.highlevelfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = neukrill_net.utils.Settings('settings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = settings.flattened_train_paths(settings.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl_names = ['pftas.pkl','contourhistogram.pkl','contourmoments.pkl','haralick.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features took 0.176540851593\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "hlf = []\n",
    "XF_list = []\n",
    "for pkl_name in pkl_names:\n",
    "    tmp = sklearn.externals.joblib.load('cache/'+pkl_name)\n",
    "    hlf += [tmp[0]]\n",
    "    XF_list += [tmp[1]]\n",
    "print(\"Loading features took {}\".format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XF = np.concatenate(XF_list,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30336, 366)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.27835052e-02,   8.24742268e-02,   1.28865979e-01,\n",
       "         2.57731959e-01,   2.21649485e-01,   1.23711340e-01,\n",
       "         5.67010309e-02,   1.03092784e-02,   2.57731959e-02,\n",
       "         9.27835052e-02,   8.24742268e-02,   1.28865979e-01,\n",
       "         2.57731959e-01,   2.21649485e-01,   1.23711340e-01,\n",
       "         5.67010309e-02,   1.03092784e-02,   2.57731959e-02,\n",
       "         7.88043478e-02,   8.69565217e-02,   1.35869565e-01,\n",
       "         1.87500000e-01,   1.19565217e-01,   8.15217391e-02,\n",
       "         1.22282609e-01,   1.03260870e-01,   8.42391304e-02,\n",
       "         9.22432432e-01,   2.94594595e-02,   1.89189189e-02,\n",
       "         1.70270270e-02,   1.00000000e-02,   1.62162162e-03,\n",
       "         5.40540541e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "         9.22432432e-01,   2.94594595e-02,   1.89189189e-02,\n",
       "         1.70270270e-02,   1.00000000e-02,   1.62162162e-03,\n",
       "         5.40540541e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "         8.10550199e-01,   8.11117413e-02,   4.42427680e-02,\n",
       "         3.14804311e-02,   1.95689166e-02,   1.04934770e-02,\n",
       "         1.70164492e-03,   8.50822462e-04,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.03626940e-02,   0.00000000e+00,   1.55440411e-02,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         5.18134702e-03,   0.00000000e+00,   1.03626940e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.03626940e-02,   5.18134702e-03,   5.18134702e-03,\n",
       "         0.00000000e+00,   5.18134702e-03,   5.18134702e-03,\n",
       "         5.18134702e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.03626940e-02,   5.18134702e-03,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.18134702e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.03626940e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.18134702e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         5.18134702e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.18134702e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.18134702e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.18134702e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.18134702e-03,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.18134702e-03,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.18134702e-03,\n",
       "         5.18134702e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.18134702e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.18134702e-03,   5.18134702e-03,   0.00000000e+00,\n",
       "         1.55440411e-02,   5.18134702e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   5.18134702e-03,   5.18134702e-03,\n",
       "         1.03626940e-02,   2.59067360e-02,   1.55440411e-02,\n",
       "         1.55440411e-02,   1.03626940e-02,   1.03626940e-02,\n",
       "         0.00000000e+00,   1.03626940e-02,   1.03626940e-02,\n",
       "         1.03626940e-02,   3.10880821e-02,   2.07253881e-02,\n",
       "         1.55440411e-02,   2.07253881e-02,   1.55440411e-02,\n",
       "         2.07253881e-02,   1.03626940e-02,   2.07253881e-02,\n",
       "         3.10880821e-02,   2.07253881e-02,   1.55440411e-02,\n",
       "         1.55440411e-02,   2.07253881e-02,   2.07253881e-02,\n",
       "         2.59067360e-02,   1.55440411e-02,   2.59067360e-02,\n",
       "         3.62694301e-02,   5.18134721e-02,   5.18134721e-02,\n",
       "         3.62694301e-02,   3.10880821e-02,   2.59067360e-02,\n",
       "         2.07253881e-02,   2.07253881e-02,   2.07253881e-02,\n",
       "         4.14507762e-02,   4.14507762e-02,   9.32642519e-02,\n",
       "         1.65803105e-01,   3.52331609e-01,   8.96373034e-01,\n",
       "         3.26424867e-01,   2.55193896e-01,   2.04862918e+00,\n",
       "         1.44272580e+00,   2.12646011e+00,  -4.62433192e+00,\n",
       "         3.15379871e+00,   3.07003271e+04,   1.39122141e+05,\n",
       "         2.54433417e+05,   2.35574674e-01,   8.21080723e+06,\n",
       "        -1.02133457e+05,   4.17133345e+04,   3.20081449e-01,\n",
       "         8.22184495e+06,  -4.12477274e-02,   2.76398107e+03,\n",
       "         1.50253777e+04,   2.12090229e-02,   6.06816516e-03,\n",
       "         3.34214333e+05,   1.16103130e+07,   3.61000000e+02,\n",
       "         1.04675000e+04,   1.95815874e+05,   7.90824091e-02,\n",
       "         5.61860172e-02,   8.67950000e+03,   2.50394000e+05,\n",
       "         7.29116057e+06,   5.92909729e-01,   1.17428038e+02,\n",
       "         8.37376309e-01,   3.60378916e+02,   8.37396275e-01,\n",
       "         5.04056774e+02,   1.32408763e+03,   1.77634694e+00,\n",
       "         2.17408130e+00,   2.42847737e-03,   1.54530917e+00,\n",
       "        -2.79362396e-01,   7.10802264e-01,   8.44503234e-03,\n",
       "         8.02833026e+01,   1.08540997e-01,   6.01075856e+00,\n",
       "         7.49707356e-03,   9.91907566e-02,   5.62402684e+01,\n",
       "         7.00702220e-02,   9.22398670e-02,   4.07591384e-05,\n",
       "         1.03418161e-01,   5.27140192e-02,   4.48146178e-02])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XF[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = sklearn.naive_bayes.GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=4.97276306152\n",
      "Accuracy=0.185917721519\n",
      "Logloss=26.1907140911\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(XF.squeeze(0)), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce with Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.f_classif, k=45).fit_transform(XF.squeeze(0), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=0.0727601051331\n",
      "Accuracy=0.308742088608\n",
      "Logloss=10.6894260686\n"
     ]
    }
   ],
   "source": [
    "my_X = X_new\n",
    "clf = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(my_X), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=38.6595170498\n",
      "Accuracy=0.525843881857\n",
      "Logloss=1.91356867834\n"
     ]
    }
   ],
   "source": [
    "clf = sklearn.ensemble.RandomForestClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=5, n_jobs=12)\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(XF.squeeze(0)), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to just the Contour Moments and Haralick features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=18.7048509121\n",
      "Accuracy=0.502043776371\n",
      "Logloss=1.9520887141\n"
     ]
    }
   ],
   "source": [
    "my_X = X_new\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=5, n_jobs=12)\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(my_X), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does slightly worse with fewer features.\n",
    "\n",
    "Maybe it was too few?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=24.9658739567\n",
      "Accuracy=0.529008438819\n",
      "Logloss=1.85792798987\n"
     ]
    }
   ],
   "source": [
    "my_X = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.f_classif, k=100).fit_transform(XF.squeeze(0), y)\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=5, n_jobs=12)\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(my_X), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=41.3399438858\n",
      "Accuracy=0.495253164557\n",
      "Logloss=2.0229527739\n"
     ]
    }
   ],
   "source": [
    "# Extra trees\n",
    "\n",
    "my_X = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.f_classif, k=100).fit_transform(XF.squeeze(0), y)\n",
    "\n",
    "clf = sklearn.ensemble.ExtraTreesClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=5)\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(my_X), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=405.716595173\n",
      "Accuracy=0.174709915612\n",
      "Logloss=4.776136176\n"
     ]
    }
   ],
   "source": [
    "# Adaboost trees\n",
    "\n",
    "my_X = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.f_classif, k=100).fit_transform(XF.squeeze(0), y)\n",
    "\n",
    "clf = sklearn.ensemble.AdaBoostClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(my_X), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterer = sklearn.cluster.DBSCAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "cluster_pred = clusterer.fit_predict(XF.squeeze(0))\n",
    "print(\"Time={}\".format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's no good.\n",
    "\n",
    "Try KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterer = sklearn.cluster.MiniBatchKMeans(n_clusters=11, max_iter=100, batch_size=100,\n",
    "                                            compute_labels=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=0.430577993393\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "cluster_pred = clusterer.fit_predict(XF.squeeze(0))\n",
    "print(\"Time={}\".format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(y))\n",
    "y_ = np.array(y)\n",
    "class_clusters = np.ones((n_classes)) * -1\n",
    "\n",
    "for class_index in range(n_classes):\n",
    "    li = (y_ == class_index)\n",
    "    class_clusters[class_index] = scipy.stats.mode(cluster_pred[li])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  5.,  3.,  5.,\n",
       "        3.,  3.,  3.,  0.,  3.,  3.,  3.,  3.,  3.,  3.,  0.,  3.,  3.,\n",
       "        3.,  3.,  7.,  3.,  3.,  8.,  3.,  3.,  3.,  3.,  3.,  3.,  1.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  5.,  0.,  0.,  3.,  3.,  4.,  1.,\n",
       "        4.,  3.,  3.,  3.,  1.,  1.,  1.,  3.,  1.,  3.,  1.,  1.,  1.,\n",
       "        4.,  3.,  3.,  0.,  3.,  3.,  4.,  7.,  0.,  1.,  7.,  3.,  3.,\n",
       "        3.,  3.,  5.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  0.,  3.,  3.,\n",
       "        0.,  3.,  3.,  1.,  3.,  3.,  1.,  3.,  0.,  0.,  3.,  3.,  3.,\n",
       "        8.,  3.,  3.,  1.,  4.,  3.,  3.,  3.,  0.,  3.,  3.,  3.,  1.,\n",
       "        8.,  3.,  3.,  3.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples_per_class = [sum(y_ == class_index) for class_index in range(n_classes)]\n",
    "num_samples_per_class = np.array(num_samples_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_samples_per_cluster = np.zeros(11)\n",
    "for cluster_index in range(11):\n",
    "    li = (class_clusters == cluster_index)\n",
    "    num_samples_per_cluster[cluster_index] = sum(num_samples_per_class[li])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1260.,   1287.,      0.,  23786.,   1215.,   1677.,      0.,\n",
       "          872.,    239.,      0.,      0.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples_per_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to play around with number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterer = sklearn.cluster.MiniBatchKMeans(n_clusters=11, max_iter=5000, batch_size=1500,\n",
    "                                            compute_labels=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time=0.405395030975\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "cluster_pred = clusterer.fit_predict(XF.squeeze(0))\n",
    "print(\"Time={}\".format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(y))\n",
    "y_ = np.array(y)\n",
    "class_clusters = np.ones((n_classes)) * -1\n",
    "\n",
    "for class_index in range(n_classes):\n",
    "    li = (y_ == class_index)\n",
    "    class_clusters[class_index] = scipy.stats.mode(cluster_pred[li])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  4.,  2.,  2.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  2.,  2.,\n",
       "        2.,  8.,  8.,  2.,  8.,  8.,  2.,  8.,  8.,  8.,  1.,  8.,  8.,\n",
       "        8.,  8.,  7.,  8.,  2.,  7.,  2.,  8.,  8.,  8.,  8.,  8.,  3.,\n",
       "        8.,  2.,  8.,  8.,  2.,  8.,  9.,  1.,  2.,  2.,  8.,  2.,  7.,\n",
       "        2.,  2.,  2.,  8.,  7.,  7.,  7.,  2.,  4.,  8.,  3.,  3.,  3.,\n",
       "        2.,  2.,  2.,  4.,  8.,  8.,  2.,  7.,  2.,  3.,  7.,  2.,  8.,\n",
       "        8.,  2.,  2.,  2.,  8.,  8.,  8.,  8.,  8.,  2.,  1.,  2.,  8.,\n",
       "        3.,  2.,  2.,  3.,  8.,  2.,  3.,  8.,  2.,  2.,  2.,  2.,  2.,\n",
       "        7.,  2.,  8.,  3.,  2.,  2.,  2.,  2.,  2.,  8.,  2.,  2.,  3.,\n",
       "        7.,  8.,  8.,  8.])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_clusters = len(np.unique(cluster_pred))\n",
    "num_samples_per_cluster = np.zeros(n_clusters)\n",
    "for cluster_index in range(n_clusters):\n",
    "    li = (class_clusters == cluster_index)\n",
    "    num_samples_per_cluster[cluster_index] = sum(num_samples_per_class[li])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0.,     57.,  11615.,   1788.,    654.,      0.,      0.,\n",
       "         1354.,  14841.,     27.,      0.])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples_per_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterer = sklearn.cluster.SpectralClustering(n_clusters=8, random_state=42, n_init=10, n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-venv-auto/lib/python2.7/site-packages/sklearn/manifold/spectral_embedding_.py:226: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "4-th leading minor not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-f8759f9194cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcluster_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclusterer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time={}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-venv-auto/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-venv-auto/lib/python2.7/site-packages/sklearn/cluster/spectral.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    445\u001b[0m                                            \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                                            \u001b[0meigen_tol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meigen_tol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m                                            assign_labels=self.assign_labels)\n\u001b[0m\u001b[0;32m    448\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-venv-auto/lib/python2.7/site-packages/sklearn/cluster/spectral.pyc\u001b[0m in \u001b[0;36mspectral_clustering\u001b[1;34m(affinity, n_clusters, n_components, eigen_solver, random_state, n_init, eigen_tol, assign_labels)\u001b[0m\n\u001b[0;32m    253\u001b[0m                               \u001b[0meigen_solver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meigen_solver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                               \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                               eigen_tol=eigen_tol, drop_first=False)\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0massign_labels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'kmeans'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-venv-auto/lib/python2.7/site-packages/sklearn/manifold/spectral_embedding_.pyc\u001b[0m in \u001b[0;36mspectral_embedding\u001b[1;34m(adjacency, n_components, eigen_solver, random_state, eigen_tol, norm_laplacian, drop_first, mode)\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             lambdas, diffusion_map = lobpcg(laplacian, X, tol=1e-15,\n\u001b[1;32m--> 303\u001b[1;33m                                             largest=False, maxiter=2000)\n\u001b[0m\u001b[0;32m    304\u001b[0m             \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiffusion_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-venv-auto/lib/python2.7/site-packages/scipy/sparse/linalg/eigen/lobpcg/lobpcg.pyc\u001b[0m in \u001b[0;36mlobpcg\u001b[1;34m(A, X, B, M, Y, tol, maxiter, largest, verbosityLevel, retLambdaHistory, retResidualNormsHistory)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;31m# B-orthonormalize the preconditioned residuals.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb_orthonormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactiveBlockVectorR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         \u001b[0mactiveBlockVectorR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactiveBlockVectorBR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-venv-auto/lib/python2.7/site-packages/scipy/sparse/linalg/eigen/lobpcg/lobpcg.pyc\u001b[0m in \u001b[0;36mb_orthonormalize\u001b[1;34m(B, blockVectorV, blockVectorBV, retInvR)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mblockVectorBV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblockVectorV\u001b[0m  \u001b[1;31m# Shared data!!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[0mgramVBV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblockVectorV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblockVectorBV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m     \u001b[0mgramVBV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgramVBV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m     \u001b[0mgramVBV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgramVBV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;31m# gramVBV is now R^{-1}.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-venv-auto/lib/python2.7/site-packages/scipy/linalg/decomp_cholesky.pyc\u001b[0m in \u001b[0;36mcholesky\u001b[1;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m     80\u001b[0m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n\u001b[1;32m---> 81\u001b[1;33m                             check_finite=check_finite)\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/inf.ed.ac.uk/user/s11/s1145806/Documents/git/neukrill-venv-auto/lib/python2.7/site-packages/scipy/linalg/decomp_cholesky.pyc\u001b[0m in \u001b[0;36m_cholesky\u001b[1;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpotrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverwrite_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%d-th leading minor not positive definite\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         raise ValueError('illegal value in %d-th argument of internal potrf'\n",
      "\u001b[1;31mLinAlgError\u001b[0m: 4-th leading minor not positive definite"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "cluster_pred = clusterer.fit_predict(XF.squeeze(0))\n",
    "print(\"Time={}\".format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterer = sklearn.cluster.AgglomerativeClustering(n_clusters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "cluster_pred = clusterer.fit_predict(XF.squeeze(0))\n",
    "print(\"Time={}\".format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(XF.squeeze(0)), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XF.squeeze(0)[:,0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try SCV on a single feature element from the vector\n",
    "\n",
    "clf = sklearn.svm.SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(XF.squeeze(0)[:,0:1]), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Naive Bayes on a single feature element\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(XF.squeeze(0)[:,0:1]), y, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Time={}\".format(time.time()-t0))\n",
    "t0 = time.time()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Time={}\".format(time.time()-t0))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = sklearn.svm.SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(XF.squeeze(0)), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Non-linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-vs-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = sklearn.svm.SVC(probability=True, random_state=42)\n",
    "\n",
    "t0 = time.time()\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(\n",
    "    sklearn.preprocessing.StandardScaler().fit_transform(XF.squeeze(0)), y, test_size=0.5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"Time={}\".format(total))\n",
    "\n",
    "print(\"Accuracy={}\".format(clf.score(X_test, y_test)))\n",
    "print(\"Logloss={}\".format(sklearn.metrics.log_loss(y_test, clf.predict_proba(X_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
